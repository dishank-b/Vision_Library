# Algorithms

##  REINFORCE \(Monte Carlo Policy Gradient\)

![](../../../.gitbook/assets/image%20%28125%29.png)

* This algorithm does not work very well. 
* **It is said to have very high variance. Hence convergence issues.**
* It can work with POMDPs as it is, which is not the case with Actor-Critic or Value iteration. 

### Example: When we have Gaussian Policy

![](../../../.gitbook/assets/image%20%28115%29.png)







